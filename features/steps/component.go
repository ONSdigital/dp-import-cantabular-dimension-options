package steps

import (
	"context"
	"errors"
	"fmt"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"

	componenttest "github.com/ONSdigital/dp-component-test"
	"github.com/ONSdigital/dp-import-cantabular-dimension-options/config"
	"github.com/ONSdigital/dp-import-cantabular-dimension-options/service"
	kafka "github.com/ONSdigital/dp-kafka/v2"
	"github.com/ONSdigital/log.go/v2/log"
	"github.com/maxcnunes/httpfake"
)

var (
	BuildTime string = "1625046891"
	GitCommit string = "7434fe334d9f51b7239f978094ea29d10ac33b16"
	Version   string = ""
)

type Component struct {
	componenttest.ErrorFeature
	apiFeature    *componenttest.APIFeature
	DatasetAPI    *httpfake.HTTPFake
	ImportAPI     *httpfake.HTTPFake
	CantabularSrv *httpfake.HTTPFake
	producer      kafka.IProducer
	consumer      kafka.IConsumerGroup
	errorChan     chan error
	svc           *service.Service
	cfg           *config.Config
	wg            *sync.WaitGroup
	signals       chan os.Signal
}

func NewComponent() *Component {
	c := &Component{
		errorChan: make(chan error),
		wg:        &sync.WaitGroup{},
	}
	c.DatasetAPI = httpfake.New(httpfake.WithTesting(c))
	c.ImportAPI = httpfake.New(httpfake.WithTesting(c))
	c.CantabularSrv = httpfake.New(httpfake.WithTesting(c))
	return c
}

// initService initialises the server, the mocks and waits for the dependencies to be ready
func (c *Component) initService(ctx context.Context) error {
	// register interrupt signals
	c.signals = make(chan os.Signal, 1)
	signal.Notify(c.signals, os.Interrupt, syscall.SIGTERM)

	// Read config
	cfg, err := config.Get()
	if err != nil {
		return nil
	}

	log.Info(ctx, "config read", log.Data{"cfg": cfg})

	cfg.DatasetAPIURL = c.DatasetAPI.ResolveURL("")
	cfg.CantabularURL = c.CantabularSrv.ResolveURL("")
	cfg.ImportAPIURL = c.ImportAPI.ResolveURL("")

	// producer for triggering test events
	if c.producer, err = kafka.NewProducer(
		ctx,
		cfg.KafkaAddr,
		cfg.KafkaCategoryDimensionImportTopic,
		kafka.CreateProducerChannels(),
		&kafka.ProducerConfig{
			KafkaVersion:    &cfg.KafkaVersion,
			MaxMessageBytes: &cfg.KafkaMaxBytes,
		},
	); err != nil {
		return fmt.Errorf("error creating kafka producer: %w", err)
	}

	// consumer for receiving instance complete events (expected to be generated by the service under test)
	// use kafkaOldest to make sure we consume all the messages
	kafkaOffset := kafka.OffsetOldest
	if c.consumer, err = kafka.NewConsumerGroup(
		ctx,
		cfg.KafkaAddr,
		cfg.KafkaInstanceCompleteTopic,
		"category-dimension-import-group",
		kafka.CreateConsumerGroupChannels(1),
		&kafka.ConsumerGroupConfig{
			KafkaVersion: &cfg.KafkaVersion,
			Offset:       &kafkaOffset,
		},
	); err != nil {
		return fmt.Errorf("error creating kafka consumer: %w", err)
	}

	// start kafka logging go-routines
	c.producer.Channels().LogErrors(ctx, "component producer")
	c.consumer.Channels().LogErrors(ctx, "component consumer")

	// Create service and initialise it
	c.svc = service.New()
	if err = c.svc.Init(context.Background(), cfg, BuildTime, GitCommit, Version); err != nil {
		return fmt.Errorf("unexpected service Init error in NewComponent: %w", err)
	}

	c.cfg = cfg

	// wait for producer and consumer to be ready
	<-c.producer.Channels().Ready
	log.Info(ctx, "component-test kafka producer ready")
	<-c.consumer.Channels().Ready
	log.Info(ctx, "component-test kafka consumer ready")

	return nil
}

func (c *Component) startService(ctx context.Context) {
	defer c.wg.Done()
	c.svc.Start(context.Background(), c.errorChan)

	// blocks until an os interrupt or a fatal error occurs
	select {
	case err := <-c.errorChan:
		err = fmt.Errorf("service error received: %w", err)
		c.svc.Close(ctx)
		panic(fmt.Errorf("unexpected error received from errorChan: %w", err))
	case sig := <-c.signals:
		log.Info(ctx, "os signal received", log.Data{"signal": sig})
	}
	if err := c.svc.Close(ctx); err != nil {
		panic(fmt.Errorf("unexpected error during service graceful shutdown: %w", err))
	}
}

// drainTopic drains the topic of any residual messages between scenarios.
// Prevents future tests failing if previous tests fail unexpectedly and
// leave messages in the queue.
func (c *Component) drainTopic(ctx context.Context) error {
	var msgs []interface{}

	defer func() {
		log.Info(ctx, "drained topic", log.Data{
			"len":      len(msgs),
			"messages": msgs,
		})
	}()

	for {
		select {
		case <-time.After(time.Second * 1):
			return nil
		case msg, ok := <-c.consumer.Channels().Upstream:
			if !ok {
				return errors.New("upstream channel closed")
			}

			msgs = append(msgs, msg)
			msg.Commit()
			msg.Release()
		}
	}
}

// Close kills the application under test, and then it shuts down the testing consumer and producer.
func (c *Component) Close() {
	ctx := context.Background()

	// kill application
	c.signals <- os.Interrupt

	// wait for graceful shutdown to finish (or timeout)
	c.wg.Wait()

	// stop listening to consumer
	if err := c.consumer.StopListeningToConsumer(ctx); err != nil {
		log.Error(ctx, "error while stop listening to kafka consumer", err)
	}

	// drain topic so that next test case starts from a known state
	if err := c.drainTopic(ctx); err != nil {
		log.Error(ctx, "error draining topic", err)
	}

	// close producer
	if err := c.producer.Close(ctx); err != nil {
		log.Error(ctx, "error closing kafka producer", err)
	}

	// close consumer
	if err := c.consumer.Close(ctx); err != nil {
		log.Error(ctx, "error closing kafka consumer", err)
	}
}

// Reset initialises the service under test, the api mocks and then starts the service
func (c *Component) Reset() error {
	ctx := context.Background()

	if err := c.initService(ctx); err != nil {
		return fmt.Errorf("failed to initialise service: %w", err)
	}

	c.DatasetAPI.Reset()
	c.ImportAPI.Reset()
	c.CantabularSrv.Reset()

	// run application in separate goroutine
	c.wg.Add(1)
	go c.startService(ctx)

	return nil
}
